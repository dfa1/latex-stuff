\documentclass{article}
\RequirePackage{amssymb}
\RequirePackage{amsmath}
\usepackage[latin1]{inputenc}
\usepackage{url}
\usepackage{bbding} %% per usare \Cross
\usepackage{stmaryrd}

\title{Sul Metodo Iterativo di Jacobi per il calcolo di autovalori}
\author{Davide Angelocola}


\begin{document}
\maketitle
\begin{abstract}
Si presentano vari criteri di enumerazione del pivot da usare nel Metodo Iterativo di Jacobi per la diagonalizzazione di una matrice.
\end{abstract}

\section{Introduzione}

Il metodo di Jacobi per il calcolo degli autovalori di una matrice simmetrica è un algoritmo numerico iterativo. 

Sia $A$ una matrice $nxn$ simmetrica. Si definisce \cite{difiore} quindi la serie di iterazioni definita da:

$$
A_0 = A \longrightarrow A_1 = S_1^TA_0S_1 \longrightarrow ... \longrightarrow A_k = S_k^TA_{k-1}S_k.
$$ 

e si sceglie $S_k$ in modo tale che:

\begin{enumerate}
  \item $S_k^T = S_k^{-1}$ con $A_k$ simile e simmetrica a $A_{k-1}$
  \item $(A_k)_{p_k q_k} = 0$   
\end{enumerate} 

Il presente documento indaga sui criteri di scelta di $p_k$ e $q_k$ per i quali il metodo converge. Per ogni criterio di scelta si dimostra che:

$$
\{A_k\}_{k=0}^{+\infty}
$$

$$
(A_k)_{p_k q_k} \longrightarrow 0, p_k \ne q_k
$$

$$
(A_k)_{p_k q_k} \longrightarrow \lambda, p_k = q_k
$$

Nella sezione \ref{sec:othermethods} presenteremo dei metodi iterativi diversi da quello di Jacobi.

\section{Criterio modulo più grande}

Al generico passo si sceglie l'elemento più grande in modulo del passo precedente. La dimostrazione di convergenza del metodo di Jacobi con questo criterio di scelta del pivot è discussa in \cite{difiore}. Inoltre la convergenza del metodo è quadratica:

$$
da scrivere
$$

\section{Criterio sequenziale}

Al generico passo si scelgono due indici $p_k$ e $q_k$ tali che:

$$
p_k < q_k
$$

In questo modo si ottengono, in sequenza tutti gli elementi sopra la diagionale. Ad esempio, sia $A$ una matrice $4x4$ questo criterio produce la sequenza di elementi:

$$
A_{12} A_{13} A_{14} A_{23} A_{24} A_{34}
$$ 

\'{E} evidente che la sequenza dei pivot per una matrice $nxn$ sia lunga $n^2 - n$ ma essi possono venire presi più di una volta?

La dimostrazione della convergenza di questo metodo è stata discussa da 
(citazione).

\section{Criterio Loizou}

Il pivot $A_{p_k q_k}$ è scelto in modo tale che la somma del quadrato degli elementi $A_{p_k q_k}$ e $A_{q_k p_k}$ sia, in modulo maggiore. La convergenza del metodo di Jacobi usando questo criterio di enumerazione dei pivot è descritta da \cite{loizou}.

\section{Criterio quasi-ciclico}

Questo critero è usato in un metodo "speciale" di Jacobi, chiamato dal suo autore V. Hari, quasi-ciclico \cite{hari}. 

\section{Criterio JBD}

JDB sta per Joint-Block Diagonlization. Ad ogni iterazione si sceglie il pivot $(p, q)$ che assicura un decremento massimo di $C_{jbd}$. Questo richiede il calcolo di tutte le differenze $boff(A_k)$.
 
\section{Criterio Hamiltoniano}

Recentemente (2008) è stato presentato un criterio di scelta per il metodo di Jacobi che sfrutta la definizione delle matrici Hamiltoniane \cite{mehl}.

Una matrice $H \in \mathbb{R}^{2nx2n}$ si dice Hamiltoniana se $H^TJ + JH = 0$ dove:

$$
J = \begin{pmatrix}
0 & I_n \cr 
-I_n & 0 \cr 
\end{pmatrix}
$$ 

o in modo equivalente:

$$
H = \begin{pmatrix}
A	 & C \cr 
D & -A^T \cr 
\end{pmatrix}
$$

dove $A$, $C$ e $D$ sono matrici $n x n$ e $C = C^T$ e $D = D^T$.
 
Infine presentiamo varie strategie di scelta dei pivot:

\begin{itemize}
  \item bottom-to-top
  \item top-to-bottom
  \item out-to-in 
\end{itemize}

\section{Parallelizzazione}

\'{E} interessante notare che il metodo di Jacobi si presta molto bene ad essere usato in ambito parallelo. 

\section{Altri metodi}\label{sec:othermethods}

Per completezza citiamo metodi iterativi "simili" a Jacobi:

\begin{itemize}
  \item calcolo della forma di Schur form per matrici complesse (Greenstadt, 1955, Eberlein, 1962/87, Stewart 1985)
  \item diagonalizzazione di matrici normali (Goldstein, Hurwitz, 1959)
  \item Hamiltonian matrices (Byers, 1986, Bunse-Gerstner Fabender, 1997)  
  \item matrici doppiamente strutturate (Fabender, Mackey, Mackey, 2001)
  \item ... molti altri ... Drmac, Veselic, ....
\end{itemize}

Tali metodi presentano tutti diverse proprietà di convergenza che non verranno trattati in questa sede.

Si presentano infine metodi alternativi a quello di Jacobi ma che producono sempre una diagonalizzazione della matrice iniziale. Tali metodi sono:

\begin{itemize}
  \item medoto della potenza 
  \item metodo di Lanczos  
  \item metodo di Arnoldi
  \item metodo di Davidson
  \item metodo di Jacobi-Davidson\cite{jacdav}
\end{itemize}

\begin{thebibliography}{5}

  \bibitem{difiore} Dispense corso Analisi Numerica 3, Di Fiore, 2007 
 
  \bibitem{jacdav} A Jacobi-Davidson Iteration Method for Linear Eigenvalue problems, G. L. G. Sleijpen \Cross, H. A. Van der Vorst \Cross , 1996

  \bibitem{loizou} On the Quadratic Convergence of the Jacobi Method for Normal Matrices, \url{http://comjnl.oxfordjournals.org/cgi/content/abstract/15/3/274}

  \bibitem{hari} Quadratic convergence of a special quasi-cyclic Jacobi method, V. Hari, \url{http://www.springerlink.com/content/gk0626782u774386}.
  
  \bibitem{mehl} Hamiltonian Jacobi methods: sweeping away convergence problems, C. Mehl, \url{http://www.math.tu-berlin.de/~mehl/talks/harburg.pdf}, 2008 

%% altre fonti
%% \url{http://en.wikipedia.org/wiki/Jacobi_eigenvalue_algorithm}
%% \url{http://www.maths.lancs.ac.uk/~gilbert/m306c/node17.html}
%% \url{http://math.fullerton.edu/mathews/n2003/JacobiMethodMod.html}
%% \url{http://www.springerlink.com/content/v8p614u1201n778t}
  
\end{thebibliography}

\end{document}
