\documentclass{article}
\RequirePackage{amssymb}
\RequirePackage{amsmath}
\usepackage[latin1]{inputenc}

\title{Appunti semplificati \\ per le Catene di Markov}
\author{Davide Angelocola}

\begin{document}
\maketitle

%% TODO: 
%%  1) definizione di rho
%%  2) persistenza/transienza in termini di rho
%%  3) catene di Ehrenfest

\section{Stati comunicanti}
$i$ comunica con $j$ se esiste un cammino finito che porta da $i$ a $j$:

$$
p_{ij}^{(n)} > 0
$$ 

\section{Classi irriducibili}

Un sottoinsieme $C$ di $S$ si dice classe chiusa se per ogni $i$:

$$
\sum_{j \in C}{p_{ij} = 1}
$$

\section{Assorbenza}

Se una classe chiusa è composta dal solo stato $i$ allora $i$ si dice stato assorbente.

\section{Equazione di Chapman-Kolmogorov}

$$
p_{ij}^{(n+m)} = \sum_{h \in S}{p_{ih}^{(n)}p_{hj}^{(m)}}
$$

se $i$ comunica con $l$ e $l$ comunica con $j$ allora $i$ comunica con $j$.

\section{Transienza}

Condizione sufficiente per la transienza: $j \rightarrow i, i \not{\rightarrow} j \Rightarrow j\ transiente $

\section{Persistenza}

%%Condizione sufficiente per la persistenza: $j \rightarrow i, \not{\rightarrow} %%j \Rightarrow j\ transiente $.

\section{Esistenza stato persistente}

Se $C$ è una catena chiusa allora esiste sempre almeno uno stato persistente.

\section{Assorbimento}

Sistema per le probabilità di assorbimento per stati finiti:
 
$$
x_i = \sum_{h \in C} p_{ih} + \sum_{h \in T \backslash C}{p_{ih}x_h}
$$

NB: la soluzione è unica e coincide con $\lambda_i = P(T_C < +\infty)$

\section{Tempi medi di assorbimento negli stati persistenti}

Per ogni stato transiente $i$:

$$
x_i = 1 + \sum_{h \in T}{p_{ih}x_h} 
$$

NB: se lo spazio degli stati è finito ammette una sola soluzione.

\section{Persistenza + Irriducibilità}

Se $S$ è finita allora esiste uno stato persistente. Se $P$ è irriducibile tutti gli stati sono persistenti. Tempo medio di ritorno è finito ed è:

$$
v_i = \frac{1}{E_i[t_i]}
$$

\section{Misure invarianti}

Un vettore probabilistico $v$ con $v_i\ \in [0,1]$ e con $i\ \in S$ si dice invariante quando, assegnato $\pi_o = v$, si ha:

$$
\pi_n = v,\ \ \forall n \ge 1
$$ 

Ogni possibile distribuzione iniziale invariante assegna $0$ agli stati transienti.

\section{Teorema di Markov/Kakutani}

Una matrice di transizione su spazio finito ammette sempre almeno una misura invariante.

\section{Ergodicità}

Se una catena è ergotica allora ammette un'unica misura invariante chiamata, misura stazionaria. Osserva che se trovo più misure invariante, ad esempio se ci sono più di due stati assorbenti, allora la dinamica non è ergotica. 

\section{Regolarità}

Se $S$ è finita e $\exists\ n \ge 1 | p_{ij}^{(n)} > 0\ \forall i, j$ allora si dice regolare. 

Condizione necessaria e sufficiente per la regolarità: $P$ irriducibile ed esista un loop.

\section{Regolarità + Ergodicità}

Se una catena è regolare allora ammette una misura stazionaria, ovvero è ergodica.

\section{Periodicità}

Se una catena irriducibile allora:

$$
t_i = t
$$ 

ovvero il periodo è lo stesso per tutti gli stati.

\section{Periodicità + Ergodicità}

Condizione necessaria e sufficiente per ergodicità di $P$ irriducibile:

$$
t = 1
$$ 

\section{Dinamiche bistocastiche}

Ogni dinamica bistocastica ammette la misura invariante uniforme.

\end{document}
